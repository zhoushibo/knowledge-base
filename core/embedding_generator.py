"""
SiliconFlow Embeddings API è°ƒç”¨
ç›´æ¥è°ƒç”¨ SiliconFlow API ç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆä¸é€šè¿‡ Gatewayï¼‰
å‚è€ƒï¼šAPI_CONFIG_FINAL.json ä¸­çš„ siliconflow é…ç½®
"""
import os
import logging
import hashlib
import json
import asyncio
from typing import List, Optional, Dict
from pathlib import Path
import aiohttp

logger = logging.getLogger(__name__)


class SiliconFlowEmbeddingGenerator:
    """SiliconFlow Embeddings ç”Ÿæˆå™¨ï¼ˆç›´æ¥ API è°ƒç”¨ï¼‰"""
    
    def __init__(self, api_key: Optional[str] = None, cache_path: Optional[str] = None):
        """
        åˆå§‹åŒ– SiliconFlow Embeddings ç”Ÿæˆå™¨
        
        Args:
            api_key: SiliconFlow API Keyï¼ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            cache_path: ç¼“å­˜æ–‡ä»¶è·¯å¾„
        """
        self.api_key = api_key or os.getenv("SILICONFLOW_API_KEY")
        
        # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œä½¿ç”¨ API_CONFIG_FINAL.json ä¸­çš„ Key
        if not self.api_key:
            try:
                import json
                # å°è¯•å¤šä¸ªå¯èƒ½çš„ä½ç½®
                possible_paths = [
                    os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))), "openclaw_async_architecture", "API_CONFIG_FINAL.json"),
                    os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))), "openclaw_async_architecture", "API_CONFIG_FINAL.json"),
                ]
                for config_path in possible_paths:
                    if os.path.exists(config_path):
                        with open(config_path, 'r', encoding='utf-8') as f:
                            config = json.load(f)
                            self.api_key = config['api_configs']['siliconflow']['api_key']
                            logger.info(f"ä» API_CONFIG_FINAL.json åŠ è½½ SiliconFlow API Key: {config_path}")
                        break
            except Exception as e:
                logger.warning(f"æ— æ³•ä»é…ç½®æ–‡ä»¶åŠ è½½ SiliconFlow API Key: {e}")
        
        if not self.api_key:
            logger.error("SILICONFLOW_API_KEY æœªé…ç½®ï¼ŒåµŒå…¥ç”Ÿæˆå°†å¤±è´¥")
        
        self.base_url = "https://api.siliconflow.cn/v1"
        self.model = "BAAI/bge-large-zh-v1.5"
        self.cache_path = Path(cache_path) if cache_path else Path("./data/embedding_cache.json")
        self.cache: Dict[str, List[float]] = {}
        
        # åŠ è½½ç¼“å­˜
        if self.cache_path and self.cache_path.exists():
            try:
                with open(self.cache_path, 'r', encoding='utf-8') as f:
                    self.cache = json.load(f)
                logger.info(f"å·²åŠ è½½åµŒå…¥ç¼“å­˜ï¼š{len(self.cache)} æ¡")
            except Exception as e:
                logger.warning(f"åŠ è½½ç¼“å­˜å¤±è´¥ï¼š{e}")
    
    def _get_cache_key(self, text: str) -> str:
        """ç”Ÿæˆæ–‡æœ¬çš„ç¼“å­˜é”®ï¼ˆSHA256 å“ˆå¸Œï¼‰"""
        return hashlib.sha256(text.encode('utf-8')).hexdigest()
    
    def _save_cache(self):
        """ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶"""
        if self.cache_path:
            try:
                self.cache_path.parent.mkdir(parents=True, exist_ok=True)
                with open(self.cache_path, 'w', encoding='utf-8') as f:
                    json.dump(self.cache, f, ensure_ascii=False, indent=2)
                logger.debug(f"å·²ä¿å­˜åµŒå…¥ç¼“å­˜ï¼š{len(self.cache)} æ¡")
            except Exception as e:
                logger.warning(f"ä¿å­˜ç¼“å­˜å¤±è´¥ï¼š{e}")
    
    def _split_text(self, text: str, max_chars: int = 300) -> List[str]:
        """
        å°†é•¿æ–‡æœ¬åˆ†å‰²æˆå¤šä¸ªç‰‡æ®µï¼ˆæŒ‰å­—ç¬¦æ•°ï¼Œä¿å®ˆä¼°è®¡ token æ•°ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            max_chars: æ¯ä¸ªç‰‡æ®µçš„æœ€å¤§å­—ç¬¦æ•°ï¼ˆSiliconFlow é™åˆ¶ 512 tokensï¼Œä¿å®ˆè®¾ä¸º 300 å­—ç¬¦ï¼‰
            
        Returns:
            æ–‡æœ¬ç‰‡æ®µåˆ—è¡¨
        """
        # ç®€å•æŒ‰å­—ç¬¦åˆ†å‰²ï¼ˆä¸­æ–‡ 1 å­—ç¬¦â‰ˆ1 tokenï¼Œç•™ 70% ä½™é‡ï¼‰
        if len(text) <= max_chars:
            return [text]
        
        # æŒ‰å¥å­åˆ†å‰²ï¼ˆä¿æŒè¯­ä¹‰å®Œæ•´ï¼‰
        import re
        sentences = re.split(r'([ã€‚ï¼ï¼Ÿï¼ï¼Ÿ\n]+)', text)
        
        chunks = []
        current_chunk = []
        current_length = 0
        
        for sentence in sentences:
            sentence_length = len(sentence)
            if current_length + sentence_length > max_chars and current_chunk:
                # å½“å‰å—å·²æ»¡ï¼Œå¼€å§‹æ–°å—
                chunks.append(''.join(current_chunk))
                current_chunk = [sentence]
                current_length = sentence_length
            else:
                current_chunk.append(sentence)
                current_length += sentence_length
        
        if current_chunk:
            chunks.append(''.join(current_chunk))
        
        return chunks if chunks else [text]
    
    async def generate_async(self, text: str) -> List[float]:
        """
        ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡ï¼ˆå¼‚æ­¥ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            åµŒå…¥å‘é‡ï¼ˆ1024 ç»´ï¼‰
        """
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(text)
        if cache_key in self.cache:
            logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„åµŒå…¥ï¼š{cache_key[:8]}...")
            return self.cache[cache_key]
        
        # åˆ†å‰²é•¿æ–‡æœ¬
        chunks = self._split_text(text)
        
        if len(chunks) == 1:
            # çŸ­æ–‡æœ¬ï¼Œç›´æ¥ç”Ÿæˆ
            embedding = await self._generate_single_chunk(chunks[0])
        else:
            # é•¿æ–‡æœ¬ï¼Œåˆ†æ®µç”Ÿæˆåå–å¹³å‡
            logger.info(f"é•¿æ–‡æœ¬åˆ†å‰²ä¸º {len(chunks)} ä¸ªç‰‡æ®µ")
            embeddings = []
            for i, chunk in enumerate(chunks):
                logger.debug(f"å¤„ç†ç‰‡æ®µ {i+1}/{len(chunks)}")
                emb = await self._generate_single_chunk(chunk)
                embeddings.append(emb)
            
            # å¹³å‡ pooling
            embedding = [
                sum(emb[i] for emb in embeddings) / len(embeddings)
                for i in range(len(embeddings[0]))
            ]
        
        # ç¼“å­˜ç»“æœ
        self.cache[cache_key] = embedding
        self._save_cache()
        
        return embedding
    
    async def _generate_single_chunk(self, text: str) -> List[float]:
        """
        ç”Ÿæˆå•ä¸ªæ–‡æœ¬ç‰‡æ®µçš„åµŒå…¥å‘é‡
        
        Args:
            text: æ–‡æœ¬ç‰‡æ®µï¼ˆå¿…é¡» < 512 tokensï¼‰
            
        Returns:
            åµŒå…¥å‘é‡
        """
        try:
            async with aiohttp.ClientSession() as session:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                payload = {
                    "model": self.model,
                    "input": text,
                    "encoding_format": "float"
                }
                
                logger.debug(f"è°ƒç”¨ SiliconFlow APIï¼š{text[:30]}...")
                async with session.post(
                    f"{self.base_url}/embeddings",
                    headers=headers,
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    if response.status != 200:
                        error_text = await response.text()
                        raise Exception(f"SiliconFlow API é”™è¯¯ ({response.status}): {error_text}")
                    
                    result = await response.json()
                    embedding = result['data'][0]['embedding']
                    return embedding
                    
        except Exception as e:
            logger.error(f"åµŒå…¥ç”Ÿæˆå¤±è´¥ï¼š{e}")
            # Fallbackï¼šè¿”å›é›¶å‘é‡
            return [0.0] * 1024
    
    def generate(self, text: str) -> List[float]:
        """
        ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            åµŒå…¥å‘é‡ï¼ˆ1024 ç»´ï¼‰
        """
        return asyncio.run(self.generate_async(text))
    
    def generate_batch(self, texts: List[str]) -> List[List[float]]:
        """
        æ‰¹é‡ç”ŸæˆåµŒå…¥å‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        logger.info(f"å¼€å§‹æ‰¹é‡ç”ŸæˆåµŒå…¥ï¼š{len(texts)} æ¡æ–‡æœ¬")
        embeddings = []
        for i, text in enumerate(texts):
            logger.debug(f"å¤„ç† {i+1}/{len(texts)}")
            embedding = self.generate(text)
            embeddings.append(embedding)
        logger.info(f"æ‰¹é‡ç”Ÿæˆå®Œæˆï¼š{len(embeddings)}/{len(texts)} æˆåŠŸ")
        return embeddings


# å…¼å®¹æ€§åˆ«å
EmbeddingGenerator = SiliconFlowEmbeddingGenerator


# æµ‹è¯•
async def main():
    """æµ‹è¯• SiliconFlow Embeddings"""
    print("=" * 80)
    print("ğŸ§ª SiliconFlow Embeddings æµ‹è¯•")
    print("=" * 80)
    
    generator = SiliconFlowEmbeddingGenerator()
    
    # æµ‹è¯• 1ï¼šå¥åº·æ£€æŸ¥
    print("\n1ï¸âƒ£ API Key æ£€æŸ¥...")
    if generator.api_key:
        print(f" âœ… API Key å·²é…ç½®ï¼š{generator.api_key[:15]}...")
    else:
        print(f" âŒ API Key æœªé…ç½®")
        return
    
    # æµ‹è¯• 2ï¼šç”ŸæˆåµŒå…¥
    print("\n2ï¸âƒ£ ç”Ÿæˆæµ‹è¯•åµŒå…¥...")
    test_text = "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡æœ¬ï¼Œç”¨äºéªŒè¯ SiliconFlow Embeddings API"
    embedding = await generator.generate_async(test_text)
    print(f" âœ… åµŒå…¥ç»´åº¦ï¼š{len(embedding)}")
    print(f" å‰ 10 ä¸ªå€¼ï¼š{embedding[:10]}")
    
    # æµ‹è¯• 3ï¼šç¼“å­˜æµ‹è¯•
    print("\n3ï¸âƒ£ ç¼“å­˜æµ‹è¯•...")
    embedding2 = await generator.generate_async(test_text)
    if embedding == embedding2:
        print(f" âœ… ç¼“å­˜ç”Ÿæ•ˆï¼Œç»“æœä¸€è‡´")
    else:
        print(f" âŒ ç¼“å­˜æœªç”Ÿæ•ˆ")
    
    print("\n" + "=" * 80)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
